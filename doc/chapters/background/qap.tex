\section{Quadratic Assignment Problem}
\label{section:background_qap}

\subsection{History and importance with examples (2)}

The Quadratic Assignment Problem is an enormous challenge in combinatorial optimization.
Its history starts with Tjalling Koopmans and Martin Beckmann, who presented a book named \textit{Assignment Problems and the Location of Economic Activities} in 1957 \cite{koopmans-beckmann1957}.
They have focused on the allocation of indivisible resources using the assignment of plants to location as an example.
Two problems were considered, first in which the transportation costs between plants could be ignored and second where the costs are included.

Ignoring the prices shows a relatively simple problem.
The task is to assign into pairs two sets of an equal number $n$ of similar elements.
Each assignment has a different score and after choosing all elements, the sum of scores is calculated.
The objective is to achieve the highest result.
Such dilemma is named linear assignment problem.

Companies often have many tasks with different difficulties for their workers.
Each employee could do the task more or less with the likewise result, which will be the rate of the pairing.
Picking the most fitting person for the specific duty could be a valid example of this simplistic problem.
However, this expects that each person is suitable to do the activity alone.
Adding that tasks hinge on each other makes selection less trivial.

Introducing an assumption that some elements from one set are dependent on other elements from the same set complicates greatly linear assignment problem and presents quadratic assignment problem.
In this situation, we have two sets as before and a matrix with weights, where each matrix's element represents one combination of assignment.
Here, choosing the solution for even a small number of elements could be demanding.

Nonetheless, the problem's importance could be shown by real life patterns existing in many fields of studies.

In production, assigning different factories to locations is one of them.
Plenty of companies need to divide responsibilities between each facility, so they could create various parts of a product, which would be later assembled together at the main branch.
The factories need to communicate constantly and allow movement of items between them.
Here, the essential factor is the distance.
The most dependent branches should be closer to each other in order to fasten production.
It fits perfectly the presented dilemma because minimizing the total cost of transportation could be achieved only by allocating items smartly.
It also matches the model - there are two sets, locations, and factories, with an equal number of elements and facilities dependent on others.

In electronics, the backboard wiring problem could be an example.
Placement of distinctive elements on the backboard is not a trivial task.
Items contingent on others creating a net connected by wire.
The longer the coil, the resistance is bigger.
This affects the performance of the whole electrical network and minimization is indicated.

In the service industry, an example could be locating distinct departments.
Similar to factories and location, here, offices and floors or rooms are allocated.

\subsection{Math definition (1)}

Let m be positive integer and $M = { 1, 2, ..., m }$. The Quadratic Assignment Problem (QAP) can be formulated as
\begin{align}
  \text{maximize} &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} a_{ijpq}x_{ij}x_{pq} + \sum_{i \in M} \sum_{j \in M} b_{ij} x_{ij} \\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M
\end{align}

This formulation is the most generalized model of quadratic assignment problem.
It could have been defined differently, however, this shows the objective function as an quadratic one, which clearly indicated the name.

\subsection{Known algorithms (11-16)}

\subsubsection{Exact solutions (2)}
\subsubsection{Linearizations (3-5)}

A great approach to resolve such complex problem is to reduce it to linear programming problem.
The first to transform the problem was Lawler, who represented it by an equivalent 0-1 linear programming problem and facilities the computations \cite{lawler1963}.

Defining $n^4$ variables $y_{ijpq}$ as $n^2$ variables $x_{ij}$ where
\begin{equation}
y_{ijpq} = x_{ij}x_{pq}
\end{equation}
the problem can be linearized and stated as
\begin{align}
  \text{minimize} &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} a_{ijpq}y_{ijpq} + \sum_{i \in M} \sum_{j \in M} b_{ij} x_{ij} \\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M \\
  &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} y_{ijpq} = m^2 \; \\
  &\null x_{ij} + x_{pq} - 2y_{ijpq} \leq 0, \; i, j, p, q \in M \\
  &\null y_{ijij} = 0 \; or \; 1, \; i, j, p, q \in M \\
\end{align}

drafts below......

Kaufmann and Broeckx

\begin{align}
  \text{minimize} &\null \sum_{i \in M} \sum_{j \in M} w_{ij}\\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M \\
  &\null c_{ij}x_{ij} + \sum_{p \in M} \sum_{q \in M} a_{ijpq}x_{pq} - w{ij} \geq c_{ij} = 0 \; i, j \in M \\
  &\null w_{ij} \geq 0, \; i, j \in M \\
\end{align}

Frieze and Yadegar

\begin{align}
  \text{minimize} &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} a_{ijpq}y_{ijpq} \\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M \\
  &\null \sum_{i \in M} y_{ijpq} = x_{pq}, \; j, p, q \in M \\
  &\null \sum_{j \in M} y_{ijpq} = x_{pq}, \; i, p, q \in M \\
  &\null \sum_{p \in M} y_{ijpq} = x_{ij}, \; i, j, q \in M \\
  &\null \sum_{q \in M} y_{ijpq}= x_{ij}, \; i, j, p \in M \\
  &\null y_{ijij} = x_{ij}, \; i, j \in M \\
  &\null 1 \geq y_{ijpq} \geq 0, \; i, j, p, q \in M
\end{align}

Adams and Johnson

\begin{align}
  \text{minimize} &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} a_{ijpq}y_{ijpq} \\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M \\
  &\null \sum_{i \in M} y_{ijpq} = x_{pq}, \; j, p, q \in M \\
  &\null \sum_{j \in M} y_{ijpq} = x_{pq}, \; i, p, q \in M \\
  &\null y_{ijpq} = x_{pqij}, \; i, j, p, q \in M \\
  &\null y_{ijpq} \geq 0, \; i, j, p, q \in M
\end{align}

\subsubsection{Metaheuristics (6-8)}

\paragraph{Greedy (1)}
\paragraph{Tabu search (2)}
\paragraph{Simulated annealing (2)}
\paragraph{Ant colony (2-3)}

