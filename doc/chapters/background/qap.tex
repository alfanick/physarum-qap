\section{Quadratic Assignment Problem}
\label{section:background_qap}

The Quadratic Assignment Problem (QAP) is an enormous challenge in the combinatorial optimization.
Its history starts with Tjalling Koopmans and Martin Beckmann, who presented a book named \textit{Assignment Problems and the Location of Economic Activities} in 1957 \cite{koopmans-beckmann1957} and since the presentation of the original formulation, there were no dramatic advances in the improvement of solving methods.
They have focused on the allocation of indivisible resources using the assignment of plants to location as an example.
Two problems were considered, first in which the transportation costs between plants could be ignored and second where the costs are included.

Ignoring the prices shows a relatively simple problem.
The task is to assign into pairs two sets of an equal number $n$ of similar elements.
Each assignment has a different score and after choosing all elements, the sum of rates is calculated.
The objective is to achieve the highest result.
Such dilemma is named linear assignment problem.

Companies often have many tasks with different difficulties for their workers.
Each employee could do the task more or less with the likewise result, which will be the rate of the pairing.
Picking the most fitting person for the specific duty could be a valid example of this simplistic problem.
However, this expects that each person is suitable to do the activity alone.
Adding that tasks hinge on each other makes selection less trivial.

Introducing an assumption that some elements from one set are dependent on other elements from the same set complicates greatly linear assignment problem and presents quadratic assignment problem.
In this situation, we have two collections as before and a matrix with weights, where each matrix's element represents one combination of assignment.
Here, choosing the solution for even a small number of elements could be demanding.

The problem's importance could be shown by real life patterns existing in many fields of studies.
In production, assigning different factories to locations is one of them.
Plenty of companies need to divide responsibilities between each facility, so they could create various parts of a product, which would be later assembled together at the main branch.
The factories need to communicate constantly and allow movement of items between them.
Here, the essential factor is the distance.
The most dependent branches should be closer to each other in order to accelerate production.
It fits perfectly the presented dilemma because minimising the total cost of transportation could be achieved only by allocating items smartly.
It also matches the model - there are two sets, locations, and factories, with an equal number of elements and facilities dependent on others.

In electronics, the backboard wiring problem could be an example.
Placement of distinctive elements on the backboard is not a trivial task.
Items contingent on others creating a net connected by wire.
The longer the coil, the resistance is bigger.
This affects the performance of the whole electrical network and minimisation is indicated.

In the service industry, an example could be locating distinct departments.
Similar to factories and location, here, offices and floors or rooms are allocated.

\subsection{Mathematical definition}
The Quadratic Assignment Problem (QAP) can be generally presented as:
\begin{equation}
min \sum_{a, b \in F} w(a, b) * d( f(a), f(b))
\end{equation}

where $w$ is a weight function $w: F \times F \mapsto R$ between $m$ different facilities ($F$) and $d$ is a distance function $d: L \times L \mapsto R$ between $m$ various locations ($L$). $y = f(x)$ means assignment of the facility $x$ to location $y$.

This could be extended to a quadratic integer problem formulation:
Let $m$ be positive integer and $M = { 1, 2, ..., m }$. The Quadratic Assignment Problem (QAP) can be formulated as
\begin{align}
  \text{minimize} &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} a_{ijpq}x_{ij}x_{pq} + \sum_{i \in M} \sum_{j \in M} b_{ij} x_{ij} \\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M
\end{align}

where $a_{ijpq}$ indicates the ratio of flow between factories $i$ and $p$ and distance between their assigned locations $j = f(i)$ and $q = f(p)$.
The assignment of factory $i$ to location $j$ is symbolised by $x_{ij} = 1$.
Additionally the $b_{ij}$ is the cost of such assignment, which may or may not be taken into consideration depending on the instance of the problem.

This formulation is the most generalised model of quadratic assignment problem.
It could have been defined differently, however, this shows the objective function as a quadratic one, which clearly indicated the name.
The discrete nature and the complexity of quadratic objective function cause difficulties in finding an optimal solution thus making the problem NP-hard.
Horowitz and Sahni have proved in their book \cite{horowitz1978fundamentals} that QAP needs an exponential time algorithm to solve optimally.


\subsection{Known algorithms}
\subsubsection{Exact solutions}

The most simple method of resolving QAP is by using an enumeration, which evaluates all of the $m!$ permutations (assignments) and records the best solution \cite{frazer1997602}.
Every calculation must be done from the start.
This requires $m^2$ steps and must be computed $m!$ times, which makes it useless for bigger instances.
However, when the problem is small, it has an advantage due to simplicity - the implementation is simple and requires little memory.

Surprisingly, also the time could be improved. Franzer presented in his paper \cite{frazer1997602} that for test problem with $m=10$ the enumeration could be faster than linear programming. Comparisions of the memory usage also gave amazing results thus proving that linear or 0-1 programming are not the most efficient, therefore appropriate, solution methods in this case.

\subsubsection{Linearizations}
One approach to resolve a complex problem is to reduce it to a linear programming problem.
Unfortunately, most of the time this could be impractical even for small $m$. Lawler \cite{lawler1963} was the first to transform the problem. He represented it by an equivalent 0-1 linear programming problem and facilities the computations. He based his thinking on a travelling salesman problem looking for similarities between these two \cite{charnsethikul1988exact}.

Defining $m^4$ variables $y_{ijpq}$ as $m^2$ variables $x_{ij}$ where
\begin{equation}
y_{ijpq} = x_{ij}x_{pq}
\end{equation}
the problem can be linearised and stated as
\begin{align}
  \text{minimize} &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} a_{ijpq}y_{ijpq} + \sum_{i \in M} \sum_{j \in M} b_{ij} x_{ij} \\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M \\
  &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} y_{ijpq} = m^2 \; \\
  &\null x_{ij} + x_{pq} - 2y_{ijpq} \leq 0, \; i, j, p, q \in M \\
  &\null y_{ijij} = 0 \; or \; 1, \; i, j, p, q \in M \\
\end{align}
As the result there are $m^4 + m^2$ binary variables and $m^4 + 2 m^2 + 1$ constraints. However, Lawler's definition is still impractical for any bigger $m$.

Kaufmann and Broeckx \cite{kaufman1978algorithm} created another linearisation, which has the smallest number of variables and constraints and is based on the method suggested by Glover \cite{gueye2009linearization}.
Such manipulation reduces the complexity of the problem thus making calculations faster.
The authors rearrange the objective function into
\begin{equation}
  \sum_{i \in M} \sum_{j \in M} x_{ij} \sum_{p \in M} \sum_{q \in M} a_{ijpq} x_{pq}
\end{equation}

Afterwards they define $m^2$ new real variables
\begin{equation}
  w_{ij} := x_{ij}\sum_{p \in M} \sum_{q \in M} a_{ijpq} x_{pq}
\end{equation}

Additionally introducing $m^2$ constraints $ c_{ij} := \sum_{p \in M} \sum_{q \in M} a_{ijpq} $ the problem could be formulated as
\begin{align}
  \text{minimize} &\null \sum_{i \in M} \sum_{j \in M} w_{ij}\\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M \\
  &\null c_{ij}x_{ij} + \sum_{p \in M} \sum_{q \in M} a_{ijpq}x_{pq} - w{ij} \geq c_{ij} = 0 \; i, j \in M \\
  &\null w_{ij} \geq 0, \; i, j \in M \\
\end{align}

As the result there are $m^2$ real variables, $m^2$ binary variables and $m^2 + 2m$ constraints.
This improves slightly previous methods.
However, Kaku and Thompson \cite{kaku1986exact} reported that for small sizes, such as m = 8, the requirements become too large and optimality could not be proved.

Another linearisation was presented by Frieze and Yadegar \cite{frieze1983quadratic}.
Obtaining their mixed integer linear programming formulation could be achieved by replacing the product of binary variables by continuous variables as
\begin{equation}
  y_{ijpq} := x_{ij} x_{pq}
\end{equation}

The outcome definition is as follows
\begin{align}
  \text{minimize} &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} a_{ijpq}y_{ijpq} + \sum_{i \in M} \sum_{j \in M} b_{ij} x_{ij} \\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M \\
  &\null \sum_{i \in M} y_{ijpq} = x_{pq}, \; j, p, q \in M \\
  &\null \sum_{j \in M} y_{ijpq} = x_{pq}, \; i, p, q \in M \\
  &\null \sum_{p \in M} y_{ijpq} = x_{ij}, \; i, j, q \in M \\
  &\null \sum_{q \in M} y_{ijpq}= x_{ij}, \; i, j, p \in M \\
  &\null y_{ijij} = x_{ij}, \; i, j \in M \\
  &\null 1 \geq y_{ijpq} \geq 0, \; i, j, p, q \in M
\end{align}

In this case, there are $m^4$ real variables, $m^2$ binary variables and $m^4 + 4m^3+m^2+2m$ constraints.

Adams and Johnson \cite{adams1994improved} presented also a new 0-1 linear integer programming formulation.
It has similarities to the previous definition.
\begin{align}
  \text{minimize} &\null \sum_{i \in M} \sum_{j \in M} \sum_{p \in M} \sum_{q \in M} a_{ijpq}y_{ijpq} \\
  \text{subject to} &\null \sum_{i \in M} x_{ij} = 1, \; j \in M \\
  &\null \sum_{j \in M} x_{ij} = 1, \; i \in M \\
  &\null x_{ij} = 0 \; or \; 1, \; i, j \in M \\
  &\null \sum_{i \in M} y_{ijpq} = x_{pq}, \; j, p, q \in M \\
  &\null \sum_{j \in M} y_{ijpq} = x_{pq}, \; i, p, q \in M \\
  &\null y_{ijpq} = x_{pqij}, \; i, j, p, q \in M \\
  &\null y_{ijpq} \geq 0, \; i, j, p, q \in M
\end{align}

So we have are $m^2$ binary variables, $m^4$ continuous variables and $m^4+2m^3+2m$ constraints.

\subsubsection{Metaheuristics}
Methods presented previously are not efficient to bigger instances.
In order to enhance the results, heuristics were used.
These approximate solution techniques have been adopted to facility combinatorial problems.
After it became clear that many of dilemmas are NP-hard, the role of heuristics increased.
Even though problems of dimensions $m > 20$ are still impractical to resolve due to high computational time, heuristics slightly improved a situation for medium size cases.

\paragraph{Greedy}

The easiest heuristic is a greedy algorithm.
In each step, a choice is made trying to locally improve at the current solution.
After a while, when the algorithm does not see a chance to improve, it stops.
The biggest disadvantage of this approach is that it may never reach global optimum due to locking in a local one. A type of such method is a steepest algorithm, where the next result is the best neighbour.


\paragraph{Genetic algorithm}

A genetic algorithm (GA) is inspired by the processes of natural selection.
It uses the analogies from a real world such as mutation, crossover and selection occurring in biology and belongs to the class of evolutionary algorithms (EA).
Its high-quality solutions make it commonly utilised.
The first genetic algorithm was presented by Holland \cite{holland1975adaptation} in 1975.

At the beginning, there is a set of initial feasible solutions, which are generated randomly.
This is called the \textit{initial population}.
An \textit{individual} is usually an element of the initial population.
From the current group, the algorithm selects a number of \textit{parents}, which are pairs of individuals.
Each pair of the parents is used to create a new feasible solution, \textit{child}, using \textit{cross-over rules}.
In the situation that the child solution is corrupted, it needs to be thrown out of the current population.
Until fulfilment of \textit{stop criterion}, which examples are run-time, a specific number of operation etc, these steps are continued.
Periodically, \textit{mutations} or \textit{immigrants} are applied to population.
They diversify the genes by modification of current individuals or replacement of them so that the overall quality of future results could be improved.

QAP has been tested with such genetic algorithm.
The first one, presented by Tate and Smith \cite{tate1995genetic}, did not achieve great results - for the small size of instances, it struggled to provide the optimal solution.

Even though it seemed that GA did not suit property for QAP, hybrid approaches showed otherwise.
They introduced local optimization tools by using \textit{tournaments}.
During the tournament, several runs of GA are initialised from different initial populations.
After stopping them, a new population is derived as a union of all the runs.
Next, the new population is given as an initial population to a new run of GA.
A good example was presented by Ahuja, Orlin, and Tiwari \cite{ahuja2000greedy} presented in 1995, which gave excellent results comparing to classical GA.

\paragraph{Tabu search}

In the beginning of heuristics, the most popular approach was Local Search.
Starting from one solution, the algorithm was improving it by applying slight modifications.
Tabu search is a metaheuristic local search method created by Glover \cite{glover1986future} in 1986, which improves the problems encountered in Local Search.
Its goal is to conquer local optimality using not only advancing the result, but also worsening.
It is achieved by remembering already visited outcomes, which helps to see promising directions for further exploration.
This approach shows the best results for QAP.

The method has few main elements, which needs to be defined in order to understand the procedure:
\begin{itemize}
  \item A \textit{search space} is a space of all possible solutions that could be visited during the search. This includes all feasible answers of the problem.
  \item A \textit{neighbourhood structure} is a subset of search space, which could be achiveved by applying a single \textit{transformation} to a current solution.
  \item A \textit{move} is an operation, which changes solution $x$ to a neighbour $x'$. In the case of QAP, the neighbourhood could be created by exchanging one pair of the solution.
  \item A \textit{tabu list} is a list containing forbidden (tabu) moves and it is updated constantly with each iteration. It consists of the records of the recent history of transformations and prevents cycling back to already visited result.
  \item An \textit{aspiration criterion} is a condition associated with each tabu move, which permits cancelling its tabu state. A most common example is allowing the tabu move if the value of the objective function is superior to current. This means that the solution was not previously visited.
\end{itemize}

At the beginning, the feasible solution is chosen and the tabu list is updated.
There is also a list of neighbours available.
The algorithm chooses the best neighbouring solution, which could be produced by a non-tabu move.
The neighbour does not have to raise the value of objective function.
Afterwards, the neighbour is the current result and the algorithm goes from the start.
The calculations are ended after \textit{termination criteria}, which could be either fixed number of iterations or the number of iterations without an improvement in the value, after reaching the threshold value.

In order to prevent visiting the same solutions over and over, a tabu criterion is used.
It identifies moves, which could lead to cycles, and adds them to the tabu list.
However, such moves could be applied if the aspiration criterion shows that they could introduce potentially winning solutions.
The tabu list is an essential change comparing to the local search.

Each tabu search algorithm could be implemented slightly differently, which impede measurement of performance.
Currently, three different tabu search methods were proposed.
First, a fixed tabu list proposed by Skorin-Kapov \cite{skorin1990tabu}.
The size of tabu list is a parameter, which needs to be tuned before starting the calculation.
It can also be dependent on the specific instance, thus such method is not recommended.
Second, a robust tabu search proposed by Taillard \cite{taillard1991robust}.
Here, a maximum and a minimum are defined and the size of the tabu list is chosen among them.
Third, a reactive tabu search proposed by Battiti and Tecchiolli \cite{battiti1994reactive}.
The size of the tabu list is adapting to the current situation.
When the cycle is identified, the size is increased according to the length of the repetition.

\paragraph{Simulated annealing}

Simulated annealing (SA) is a heuristic which searches locally a big exploration space.
The method, firstly presented by Kirkpatrick, Gelatt and Vecchi \cite{kirkpatrick1983optimization} and {\v{C}}ern{\`y} \cite{vcerny1985thermodynamical}, is based on the analogy to annealing known from metallurgy.

The first step includes generating the initial feasible solution and calculating its value using the cost function.
After that, the neighbouring result is produced and its rate estimated.
Both of them are compared, and if the cost of the neighbour is smaller than current solution then the algorithm moves to the neighbour.
Otherwise, it may move to the new solution.
The decision is made by determining \textit{acceptance probability} and opposing it to a random number.
This helps to avoid local optima.
These steps are repeated until a satisfactory solution is found or the specified number of iterations are reached.

A very important element is the acceptance probability function.
Taking into account the new cost, the old cost and the current temperature it calculates a number between 0 and 1.
The result is a guidance whether to switch solution or not.
This cost is compared with a randomly generated number from the same range.
If the acceptance probability is larger than the second number then the new current solution is the neighbour.

The temperature is another element of the algorithm.
It starts at 1.0 symbolising heat and that all particles are randomly arranged in this liquid state.
With each iteration it is multiplied by a constant typically between 0.8 and 0.99 and as the temperature decreases the probability tends to concentrate on low energy states.
This slightly decreases the value and simulates slow cooling of the metal.
It is also used as a stopping criterion - algorithm stops when the temperature reach 0.
At the end, at thermal equilibrium, the probability that a system is in a configuration $i$ with energy $E_i$ is given by Boltzmann distribution:

\begin{equation}
  p_i = \frac{exp(-\frac{E_i}{kT})}{S}
\end{equation}

Here $T$ is the absolute temperature, $k$ the Boltzmann constant, $N$ the total number of configurations and
\begin{equation}
  \sum_{i=1}^{N} p_i = 1
\end{equation}

Burkard and Rendl \cite{burkard1984thermodynamically} have applied SA to the QAP.
They have presented that if the problem could have a neighbourhood defined, it can be solved using SA, thus this algorithm is a general heuristic.
Other authors presenting SA to solve QAP are Wilhelm and Ward \cite{wilhelm1987solving} and Connolly \cite{connolly1990improved}.
Each of them defined neighbour as a solution with one pair-exchange from the current.
The difference between them is the implementation of the cooling method.
Due to the fact that SA is very dependent on its control parameters, its performance may vary.

\paragraph{Ant colony}

Ant colony heuristic is modelled on the phenomenon occurring in the environment and was originally introduced by Dorigo \cite{dorigo1992optimization} and Colorni, Dorigo, and Maniezzo \cite{dorigo1996ant}.
It tries to imitate the behaviour of an ant colony in search of food.
It bases on the fact that, when ants have multiple roads to food, they always pick the shortest one.
In general, these insects do not have high intelligence - their knowledge is limited to remembering the travel distance and reading the level of pheromones.
They are also capable of distinguishing the pheromones between their self and others.
Nevertheless, this information allows them to solve rather complex problems.

At the beginning, ants move randomly in the vicinity of their nest, guided only by coincidence.
However, after finding a food source, the lucky ant takes it back to the nest.
On its way home, it releases the trail of pheromones on the ground.
Each ant travelling the same path with food will also leave some pheromones, which will accumulate.
In the end, the intensity of the trail is proportional to the amount of food found in the source, so the largest sources would have the highest strength.
Thus, in order to bring more food home, the successors will more likely to prefer more intensive paths.

In ants behaviour, few analogies to the computational algorithms could be distinguished:
\begin{itemize}
  \item the set of feasible solutions is resembled by the search area
  \item the value of the objective function is resembled by the amount of food in sources
  \item a component of adaptive memory is resembled by the pheromone trail
\end{itemize}

The most recent algorithms provided the best results.
The nontrivial instance of QAP with size $ m = 36 $ was solved optimally by a benchmark library QAPLIB \cite{dorigo2004ant}.
This revolutionised further research and attracted scientists to analyse the usage of ant colony optimization (AOC) in case of the QAP.
AS-QAP, MMAS-QAP, ANTS-QAP are few examples of the QAP specific implementation of the AOC.

